{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path to the CSV file\n",
    "csv_file_path = r'C:\\Users\\btrok\\OneDrive\\BBall Project\\nbafinaldraftdata.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame, specifying the encoding\n",
    "# Try different encodings such as 'utf-16', 'latin1', 'cp1252', etc.\n",
    "df = pd.read_csv(csv_file_path, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name                                           Headline  \\\n",
      "0    Markelle Fultz  A versatile defender and athletic leaper who i...   \n",
      "1        Lonzo Ball  Has the potential to be the best passer in the...   \n",
      "2      Josh Jackson  Athletic, energetic two way forward whose scor...   \n",
      "3      Jayson Tatum  Combo forward with classic go to scoring poten...   \n",
      "4      De'Aaron Fox  Lightning quick point guard who constantly pre...   \n",
      "..              ...                                                ...   \n",
      "478     Baba Miller  Late blooming big who has a wings skill set a...   \n",
      "479   Reece Beekman  Low usage playmaker who can also lock down opp...   \n",
      "480     Judah Mintz  Ambidextrous playmaker who can manage games an...   \n",
      "481    Bronny James  Athletic guard still finding his way as he fol...   \n",
      "482  Thierry Darlan  Long armed sharpshooter with pull up prowess a...   \n",
      "\n",
      "                                             PlusMinus  Year  \n",
      "0    PLUSES  Controls speed of the game as a playma...  2017  \n",
      "1    PLUSES  Elite court vision and passing accurac...  2017  \n",
      "2    PLUSES  Explosive athlete who plays with balan...  2017  \n",
      "3    PLUSES  Fluid athlete with a good wingspan and...  2017  \n",
      "4    PLUSES  Speed coupled with the ability to cont...  2017  \n",
      "..                                                 ...   ...  \n",
      "478  PLUSES At 6 foot 11 with a 7 foot 2 wingspan, ...  2024  \n",
      "479  PLUSES Excellent defender who won ACC Defensiv...  2024  \n",
      "480  PLUSES Super crafty player, mainly because he ...  2024  \n",
      "481  PLUSES Good athlete with a strong frame and le...  2024  \n",
      "482  PLUSES A seamless pull up shooter from deep ra...  2024  \n",
      "\n",
      "[483 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Downloading inflect-7.2.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting more-itertools (from inflect)\n",
      "  Downloading more_itertools-10.3.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting typeguard>=4.0.1 (from inflect)\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\btrok\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from inflect) (4.11.0)\n",
      "Downloading inflect-7.2.1-py3-none-any.whl (34 kB)\n",
      "Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.2/59.2 kB ? eta 0:00:00\n",
      "Installing collected packages: typeguard, more-itertools, inflect\n",
      "Successfully installed inflect-7.2.1 more-itertools-10.3.0 typeguard-4.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\btrok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\btrok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\btrok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name                                           Headline  \\\n",
      "4     De'Aaron Fox  Lightning quick point guard who constantly pre...   \n",
      "5     Dennis Smith  His athleticism is impressive, but he doesn't ...   \n",
      "6   Jonathan Isaac  A tall, lanky, multipositional three and D ath...   \n",
      "7       Malik Monk  Supremely athletic scorer who, while undersize...   \n",
      "8  Frank Ntilikina  A defensive stopper at the point guard spot wi...   \n",
      "9  Lauri Markkanen  A tremendous perimeter scorer at the big man p...   \n",
      "\n",
      "                                           PlusMinus  Year  \n",
      "4  PLUSES Speed coupled with the ability to contr...  2017  \n",
      "5  PLUSES Explosive athlete; soars through the la...  2017  \n",
      "6  PLUSES Exciting potential to be a versatile sc...  2017  \n",
      "7  PLUSES Superb quickness. He flies up the court...  2017  \n",
      "8  PLUSES Fluid athlete with long arms and a fram...  2017  \n",
      "9  PLUSES Fluid, agile seven footer with a guard'...  2017  \n"
     ]
    }
   ],
   "source": [
    "# Initialize inflect engine\n",
    "p = inflect.engine()\n",
    "\n",
    "# Convert numbers in 'Headline' column to words\n",
    "df_copy['Headline'] = df_copy['Headline'].apply(lambda x: ' '.join([p.number_to_words(word) if word.isdigit() else word for word in x.split()]))\n",
    "\n",
    "# Convert numbers in 'PlusMinus' column to words\n",
    "df_copy['PlusMinus'] = df_copy['PlusMinus'].apply(lambda x: ' '.join([p.number_to_words(word) if word.isdigit() else word for word in x.split()]))\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df_copy.iloc[4:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to apply text preprocessing\n",
    "columns_to_preprocess = ['Headline', 'PlusMinus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lowercase\n",
    "df_copy['Name'] = df_copy['Name'].str.lower()\n",
    "df_copy['Headline'] = df_copy['Headline'].str.lower()\n",
    "df_copy['PlusMinus'] = df_copy['PlusMinus'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters and punctuation,\n",
    "# tokenize the text, remove stop words, lemmatize the words, and join tokens back\n",
    "for column in columns_to_preprocess:\n",
    "\n",
    "    \n",
    "    # Remove special characters and punctuation marks\n",
    "    df_copy[column] = df_copy[column].apply(lambda text: text.translate(str.maketrans('', '', string.punctuation)))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    df_copy[column] = df_copy[column].apply(word_tokenize)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df_copy[column] = df_copy[column].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df_copy[column] = df_copy[column].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    df_copy[column] = df_copy[column].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Save a copy of the new DataFrame\n",
    "df_copy.to_csv('preprocessed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
